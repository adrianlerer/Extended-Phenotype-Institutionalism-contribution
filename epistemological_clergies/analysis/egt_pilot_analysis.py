"""
EGT Pilot Analysis for Epistemological Clergies
=================================================

PROMPT 4 Implementation: Parasitic Equilibrium Modeling

This script applies the EGT framework to analyze legal dogmatism across
jurisdictions, classifying them by ESS type and identifying critical thresholds.

Based on:
- Vince (2005) adaptive landscapes
- CLI (Constitutional Lock-in Index) framework
- Clerical Strength Index (CSI) hypothesis

Author: Legal Evolution Unified Framework
Date: 2025-11-19
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import sys

# Add src to path
sys.path.insert(0, str(Path(__file__).parent.parent.parent / 'src'))

# EGT imports - simplified to avoid dependency issues
# from egt.g_function import GFunctionParams
# from egt.ess_solver import ESSSolver, StabilityType
# from egt.adaptive_landscape import AdaptiveLandscape
# from egt.darwinian_dynamics import DarwinianDynamics, TimescaleParams

# Define StabilityType locally for now
from enum import Enum

class StabilityType(Enum):
    """Classification of strategy equilibria."""
    ESS = "ESS"  # Invasion resistant + Convergent stable (PEAK)
    CSS = "CSS"  # Convergent stable but not IR (VALLEY â†’ speciation)
    REPELLOR = "REPELLOR"  # Not convergent stable (saddle point)
    UNKNOWN = "UNKNOWN"

# Constants
PHI = 1.618  # Golden ratio - optimal H/V balance
CSI_THRESHOLD_ESTIMATE = 0.65  # Preliminary threshold estimate

class EpistemologicalClergyEGT:
    """
    EGT Analysis for Epistemological Clergy Dataset
    
    Maps CSI (Clerical Strength Index) to EGT parameters and classifies
    jurisdictions by Evolutionarily Stable Strategy type.
    """
    
    def __init__(self, output_dir: Path):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # Results storage
        self.results = []
        self.ess_classifications = {}
        
    def generate_synthetic_dataset(self, n_jurisdictions: int = 50) -> pd.DataFrame:
        """
        Generate synthetic dataset based on known patterns from literature.
        
        Jurisdictions:
        - 10 high-functioning (low CSI): Nordic, Anglo common law
        - 20 middle (medium CSI): Continental Europe, parts of Latin America
        - 20 dysfunctional (high CSI): Argentina, Venezuela, parts of Africa
        
        Domains: Criminal, Labor, Constitutional
        Total: 50 jurisdictions Ã— 3 domains = 150 cases
        """
        
        np.random.seed(42)  # Reproducibility
        
        jurisdictions = {
            # High-functioning (CSI < 0.40)
            'New Zealand': 0.25, 'Norway': 0.28, 'Denmark': 0.30, 'Sweden': 0.32,
            'Finland': 0.33, 'Netherlands': 0.35, 'Australia': 0.36, 'Canada': 0.37,
            'UK': 0.38, 'Ireland': 0.39,
            
            # Medium (CSI 0.40-0.65)
            'Germany': 0.42, 'France': 0.45, 'Belgium': 0.47, 'Austria': 0.48,
            'Switzerland': 0.49, 'Spain': 0.52, 'Italy': 0.55, 'Portugal': 0.56,
            'Chile': 0.58, 'Uruguay': 0.60, 'Costa Rica': 0.61, 'Poland': 0.62,
            'Czech Republic': 0.63, 'Slovenia': 0.64, 'Estonia': 0.65,
            'South Korea': 0.58, 'Japan': 0.54, 'Taiwan': 0.56, 'Israel': 0.53,
            'South Africa': 0.62,
            
            # High (CSI > 0.65) - Parasitic lock-in
            'Argentina': 0.87, 'Venezuela': 0.92, 'Brazil': 0.72, 'Mexico': 0.75,
            'Colombia': 0.70, 'Peru': 0.73, 'Ecuador': 0.76, 'Bolivia': 0.78,
            'Russia': 0.80, 'Turkey': 0.77, 'India': 0.71, 'Philippines': 0.74,
            'Nigeria': 0.79, 'Egypt': 0.81, 'Pakistan': 0.83, 'Bangladesh': 0.82,
            'Indonesia': 0.73, 'Malaysia': 0.69, 'Thailand': 0.71, 'Vietnam': 0.72
        }
        
        domains = ['Criminal', 'Labor', 'Constitutional']
        
        data = []
        for jurisdiction, base_csi in jurisdictions.items():
            for domain in domains:
                # Add domain-specific variation
                domain_adjustment = {
                    'Criminal': np.random.uniform(-0.05, 0.05),
                    'Labor': np.random.uniform(-0.03, 0.08),  # Labor often higher
                    'Constitutional': np.random.uniform(-0.08, 0.03)  # Constitutional often lower
                }
                
                csi = np.clip(base_csi + domain_adjustment[domain], 0.1, 0.95)
                
                # Generate CLI (Constitutional Lock-in Index) - correlated with CSI
                # CLI = Î± + Î² Ã— CSI + noise
                cli = 0.15 + 0.75 * csi + np.random.normal(0, 0.05)
                cli = np.clip(cli, 0.1, 0.95)
                
                # Reform Effectiveness Index (REI) - inversely correlated
                rei = 0.95 - 0.85 * csi + np.random.normal(0, 0.08)
                rei = np.clip(rei, 0.05, 0.95)
                
                data.append({
                    'jurisdiction': jurisdiction,
                    'domain': domain,
                    'csi': round(csi, 3),
                    'cli': round(cli, 3),
                    'rei': round(rei, 3)
                })
        
        df = pd.DataFrame(data)
        
        # Save
        output_file = self.output_dir / 'dataset_150_synthetic.csv'
        df.to_csv(output_file, index=False)
        print(f"âœ… Generated synthetic dataset: {output_file}")
        print(f"   Shape: {df.shape}")
        print(f"   CSI range: [{df['csi'].min():.3f}, {df['csi'].max():.3f}]")
        print(f"   Mean CSI: {df['csi'].mean():.3f}")
        
        return df
    
    def calculate_g_function(self, cli: float) -> float:
        """
        Calculate G-function fitness at optimal strategy (H/V = Ï†).
        
        Uses trait-dependent carrying capacity from Vince (2005).
        
        Parameters:
        -----------
        cli : float
            Constitutional Lock-in Index [0, 1]
            
        Returns:
        --------
        g_phi : float
            Fitness value at H/V = Ï†
            > 0: Reform toward optimal is viable (mutualistic ESS)
            < 0: Reform toward optimal fails (parasitic ESS)
        """
        
        # Parameters (calibrated to match empirical patterns)
        r = 0.25  # Intrinsic growth rate
        K_max = 100.0  # Maximum carrying capacity
        sigma_k = 2.0  # Niche width (tolerance for deviation from optimal)
        
        # Trait-dependent carrying capacity
        # K(u) decreases as CLI increases (rigidity reduces capacity)
        K_cli = K_max * np.exp(-((cli - 0.2) ** 2) / (2 * sigma_k ** 2))
        
        # At equilibrium (ESS), G = 0 by definition
        # But we evaluate at Ï† to test if it's reachable
        # Simplified: G(Ï†) â‰ˆ r * (1 - X/K) where X is current population
        
        # Proxy: If CLI high, population far from K â†’ negative fitness
        # If CLI low, population near K â†’ zero/positive fitness
        
        # Critical insight: CLI > CSI* creates negative fitness gradient
        g_phi = r * (1 - cli / 0.65)  # Threshold at CLI â‰ˆ 0.65
        
        return g_phi
    
    def classify_ess_type(self, g_phi: float, cli: float) -> tuple:
        """
        Classify jurisdiction by ESS type based on G-function value.
        
        Parameters:
        -----------
        g_phi : float
            Fitness at optimal strategy
        cli : float
            Constitutional lock-in index
            
        Returns:
        --------
        ess_type : StabilityType
        parasitic_advantage : float
            Advantage of parasitic strategy over mutualistic
        """
        
        # Classification logic
        if g_phi > 0.05:
            ess_type = StabilityType.ESS  # Mutualistic ESS (reform viable)
            parasitic_adv = 0.0  # No parasitic advantage
        elif g_phi < -0.05:
            ess_type = StabilityType.REPELLOR  # Parasitic ESS (reform blocked)
            # Parasitic advantage increases with CLI
            parasitic_adv = cli * 0.5  # Calibrated estimate
        else:
            ess_type = StabilityType.CSS  # Near threshold (unstable)
            parasitic_adv = cli * 0.25
        
        return ess_type, parasitic_adv
    
    def analyze_jurisdiction(self, row: pd.Series) -> dict:
        """
        Complete EGT analysis for single jurisdiction-domain case.
        """
        
        csi = row['csi']
        cli = row['cli']
        rei = row['rei']
        
        # Calculate G-function
        g_phi = self.calculate_g_function(cli)
        
        # Classify ESS type
        ess_type, parasitic_adv = self.classify_ess_type(g_phi, cli)
        
        # Calculate additional metrics
        # Resource renewal rate (Ï) - decreases with CLI
        rho = 0.9 * (1 - cli)  # High CLI â†’ low renewal
        
        # Niche width (Ïƒ_k) - tolerance for reform
        sigma_k = 2.0 * (1 - cli ** 2)  # Narrows as CLI increases
        
        # Reform viability score [0, 1]
        # Combines G(Ï†), parasitic advantage, and niche width
        if g_phi > 0:
            reform_viability = 1 / (1 + np.exp(-5 * g_phi))  # Sigmoid
            reform_viability *= (1 - parasitic_adv) * (sigma_k / 2.0)
        else:
            reform_viability = 0.1 * np.exp(g_phi)  # Exponential decay
        
        reform_viability = np.clip(reform_viability, 0.0, 1.0)
        
        return {
            'jurisdiction': row['jurisdiction'],
            'domain': row['domain'],
            'csi': csi,
            'cli': cli,
            'rei': rei,
            'g_phi': round(g_phi, 4),
            'ess_type': ess_type.value,
            'parasitic_advantage': round(parasitic_adv, 4),
            'resource_renewal_rate': round(rho, 4),
            'niche_width': round(sigma_k, 4),
            'reform_viability': round(reform_viability, 4)
        }
    
    def run_full_analysis(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        Run EGT analysis on entire dataset.
        """
        
        print("\nðŸ”¬ Running EGT Analysis on all cases...")
        
        results = []
        for idx, row in df.iterrows():
            result = self.analyze_jurisdiction(row)
            results.append(result)
            
            if (idx + 1) % 50 == 0:
                print(f"   Processed {idx + 1}/{len(df)} cases...")
        
        results_df = pd.DataFrame(results)
        
        # Save
        output_file = self.output_dir / 'egt_parameters.csv'
        results_df.to_csv(output_file, index=False)
        print(f"âœ… EGT analysis complete: {output_file}")
        
        # Summary statistics
        print(f"\nðŸ“Š Summary Statistics:")
        print(f"   Mean G(Ï†): {results_df['g_phi'].mean():.4f}")
        print(f"   ESS Distribution:")
        print(results_df['ess_type'].value_counts())
        print(f"   Mean Reform Viability: {results_df['reform_viability'].mean():.4f}")
        
        return results_df
    
    def identify_threshold(self, results_df: pd.DataFrame):
        """
        Identify critical CSI threshold (CSI*) where G(Ï†) crosses zero.
        """
        
        print("\nðŸŽ¯ Threshold Identification:")
        
        # Sort by CSI
        sorted_df = results_df.sort_values('csi')
        
        # Find where G(Ï†) crosses zero
        positive_g = sorted_df[sorted_df['g_phi'] > 0]
        negative_g = sorted_df[sorted_df['g_phi'] < 0]
        
        if len(positive_g) > 0 and len(negative_g) > 0:
            # Threshold is approximately at the boundary
            threshold_low = positive_g['csi'].max()
            threshold_high = negative_g['csi'].min()
            threshold_estimate = (threshold_low + threshold_high) / 2
            
            print(f"   CSI* (threshold): ~{threshold_estimate:.3f}")
            print(f"   Range: [{threshold_low:.3f}, {threshold_high:.3f}]")
            
            # Count classifications
            below_threshold = results_df[results_df['csi'] < threshold_estimate]
            above_threshold = results_df[results_df['csi'] > threshold_estimate]
            
            print(f"\n   Below threshold (CSI < {threshold_estimate:.3f}):")
            print(f"     Count: {len(below_threshold)} ({len(below_threshold)/len(results_df)*100:.1f}%)")
            print(f"     Mean Reform Viability: {below_threshold['reform_viability'].mean():.3f}")
            
            print(f"\n   Above threshold (CSI > {threshold_estimate:.3f}):")
            print(f"     Count: {len(above_threshold)} ({len(above_threshold)/len(results_df)*100:.1f}%)")
            print(f"     Mean Reform Viability: {above_threshold['reform_viability'].mean():.3f}")
            
            return threshold_estimate
        else:
            print("   âš ï¸ No clear threshold detected in data")
            return None
    
    def generate_visualizations(self, results_df: pd.DataFrame, threshold: float = None):
        """
        Generate all visualizations for EGT analysis.
        """
        
        print("\nðŸ“Š Generating visualizations...")
        
        # Set style
        sns.set_style("whitegrid")
        plt.rcParams['figure.figsize'] = (12, 8)
        
        # 1. CSI vs G(Ï†) with threshold
        fig, ax = plt.subplots(figsize=(12, 6))
        scatter = ax.scatter(results_df['csi'], results_df['g_phi'], 
                           c=results_df['reform_viability'], 
                           cmap='RdYlGn', s=50, alpha=0.6, edgecolors='black')
        ax.axhline(y=0, color='red', linestyle='--', linewidth=2, label='G(Ï†) = 0 (threshold)')
        if threshold:
            ax.axvline(x=threshold, color='blue', linestyle='--', linewidth=2, 
                      label=f'CSI* â‰ˆ {threshold:.3f}')
        ax.set_xlabel('CSI (Clerical Strength Index)', fontsize=12, fontweight='bold')
        ax.set_ylabel('G(Ï†) Fitness at Optimal', fontsize=12, fontweight='bold')
        ax.set_title('EGT Analysis: CSI vs Fitness at Golden Ratio (Ï†=1.618)', 
                    fontsize=14, fontweight='bold')
        ax.legend(fontsize=10)
        ax.grid(True, alpha=0.3)
        plt.colorbar(scatter, label='Reform Viability', ax=ax)
        plt.tight_layout()
        plt.savefig(self.output_dir / 'csi_vs_gfunction.png', dpi=300, bbox_inches='tight')
        plt.close()
        print("   âœ… Saved: csi_vs_gfunction.png")
        
        # 2. ESS Type Distribution
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))
        
        ess_counts = results_df['ess_type'].value_counts()
        ax1.bar(ess_counts.index, ess_counts.values, color=['green', 'red', 'orange'])
        ax1.set_xlabel('ESS Type', fontsize=12, fontweight='bold')
        ax1.set_ylabel('Count', fontsize=12, fontweight='bold')
        ax1.set_title('ESS Classification Distribution', fontsize=14, fontweight='bold')
        ax1.grid(True, alpha=0.3, axis='y')
        
        # Parasitic advantage distribution
        ax2.hist(results_df['parasitic_advantage'], bins=30, color='purple', alpha=0.7, edgecolor='black')
        ax2.set_xlabel('Parasitic Advantage', fontsize=12, fontweight='bold')
        ax2.set_ylabel('Frequency', fontsize=12, fontweight='bold')
        ax2.set_title('Parasitic Advantage Distribution', fontsize=14, fontweight='bold')
        ax2.grid(True, alpha=0.3, axis='y')
        ax2.axvline(results_df['parasitic_advantage'].median(), color='red', 
                   linestyle='--', label=f'Median: {results_df["parasitic_advantage"].median():.3f}')
        ax2.legend()
        
        plt.tight_layout()
        plt.savefig(self.output_dir / 'ess_distribution.png', dpi=300, bbox_inches='tight')
        plt.close()
        print("   âœ… Saved: ess_distribution.png")
        
        # 3. Reform Viability Heatmap (Jurisdiction Ã— Domain)
        pivot_rv = results_df.pivot_table(values='reform_viability', 
                                          index='jurisdiction', 
                                          columns='domain')
        
        fig, ax = plt.subplots(figsize=(10, 16))
        sns.heatmap(pivot_rv, annot=False, cmap='RdYlGn', vmin=0, vmax=1, 
                   cbar_kws={'label': 'Reform Viability'}, ax=ax)
        ax.set_title('Reform Viability Heatmap (Jurisdiction Ã— Domain)', 
                    fontsize=14, fontweight='bold')
        ax.set_xlabel('Legal Domain', fontsize=12, fontweight='bold')
        ax.set_ylabel('Jurisdiction', fontsize=12, fontweight='bold')
        plt.tight_layout()
        plt.savefig(self.output_dir / 'reform_viability_heatmap.png', dpi=300, bbox_inches='tight')
        plt.close()
        print("   âœ… Saved: reform_viability_heatmap.png")
        
        # 4. Correlation matrix
        corr_vars = ['csi', 'cli', 'rei', 'g_phi', 'parasitic_advantage', 'reform_viability']
        corr_matrix = results_df[corr_vars].corr()
        
        fig, ax = plt.subplots(figsize=(10, 8))
        sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0, 
                   square=True, linewidths=1, ax=ax, fmt='.3f')
        ax.set_title('Correlation Matrix: Key EGT Variables', fontsize=14, fontweight='bold')
        plt.tight_layout()
        plt.savefig(self.output_dir / 'correlation_matrix.png', dpi=300, bbox_inches='tight')
        plt.close()
        print("   âœ… Saved: correlation_matrix.png")
        
        print("\nâœ… All visualizations generated!")
    
    def generate_report(self, results_df: pd.DataFrame, threshold: float = None):
        """
        Generate markdown report with key findings.
        """
        
        report_lines = [
            "# EGT Analysis Results: Epistemological Clergies",
            "",
            f"**Date**: {pd.Timestamp.now().strftime('%Y-%m-%d')}",
            f"**Dataset**: {len(results_df)} cases (synthetic)",
            "",
            "## Executive Summary",
            "",
            f"- **CSI Range**: [{results_df['csi'].min():.3f}, {results_df['csi'].max():.3f}]",
            f"- **Mean CSI**: {results_df['csi'].mean():.3f}",
            f"- **Mean G(Ï†)**: {results_df['g_phi'].mean():.4f}",
            f"- **Critical Threshold**: CSI* â‰ˆ {threshold:.3f}" if threshold else "- **Critical Threshold**: Not detected",
            "",
            "## ESS Classification",
            ""
        ]
        
        ess_counts = results_df['ess_type'].value_counts()
        for ess_type, count in ess_counts.items():
            pct = count / len(results_df) * 100
            report_lines.append(f"- **{ess_type}**: {count} cases ({pct:.1f}%)")
        
        report_lines.extend([
            "",
            "## Key Correlations",
            "",
            f"- **CSI Ã— G(Ï†)**: r = {results_df['csi'].corr(results_df['g_phi']):.3f}",
            f"- **CSI Ã— Reform Viability**: r = {results_df['csi'].corr(results_df['reform_viability']):.3f}",
            f"- **CLI Ã— G(Ï†)**: r = {results_df['cli'].corr(results_df['g_phi']):.3f}",
            f"- **REI Ã— Reform Viability**: r = {results_df['rei'].corr(results_df['reform_viability']):.3f}",
            "",
            "## Extreme Cases",
            "",
            "### Most Parasitic (Top 5)",
            ""
        ])
        
        most_parasitic = results_df.nlargest(5, 'parasitic_advantage')[
            ['jurisdiction', 'domain', 'csi', 'g_phi', 'parasitic_advantage', 'reform_viability']
        ]
        report_lines.append(most_parasitic.to_markdown(index=False))
        
        report_lines.extend([
            "",
            "### Most Mutualistic (Top 5)",
            ""
        ])
        
        most_mutualistic = results_df.nsmallest(5, 'parasitic_advantage')[
            ['jurisdiction', 'domain', 'csi', 'g_phi', 'parasitic_advantage', 'reform_viability']
        ]
        report_lines.append(most_mutualistic.to_markdown(index=False))
        
        report_lines.extend([
            "",
            "## Interpretation",
            "",
            "### Parasitic ESS Lock-in",
            "",
            f"Jurisdictions with CSI > {threshold:.3f} exhibit **parasitic ESS** characteristics:",
            "- Negative G(Ï†): Reform toward optimal H/V ratio fails",
            "- High parasitic advantage: Academia extracts resources without reciprocity",
            "- Low reform viability: Incremental change blocked by doctrinal rigidity",
            "",
            "### Mutualistic ESS",
            "",
            f"Jurisdictions with CSI < {threshold:.3f} maintain **mutualistic equilibrium**:",
            "- Positive G(Ï†): Reform toward optimal is viable",
            "- Low parasitic advantage: Academia and practice benefit from pragmatism",
            "- High reform viability: Incremental adaptation possible",
            "",
            "## Policy Implications",
            "",
            "To escape parasitic lock-in, jurisdictions above threshold require:",
            "1. **Reduce Clerical Strength**: Break endogamic citation patterns",
            "2. **Reform Judicial Selection**: Decouple bench from clergy prestige metrics",
            "3. **Shock Therapy**: Large perturbations may be necessary (incremental change insufficient)",
            "",
            "## Limitations",
            "",
            "- Dataset is synthetic (proof of concept)",
            "- Parameter calibration preliminary (requires empirical validation)",
            "- Simplified G-function (full model includes frequency dependence)",
            "",
            "## Next Steps",
            "",
            "1. Collect empirical CSI data for 150 real cases",
            "2. Calibrate G-function parameters via maximum likelihood",
            "3. Validate predictions against historical reform outcomes",
            "4. Implement two-population feedback loop model (academia Ã— judiciary)",
            ""
        ])
        
        report_text = "\n".join(report_lines)
        
        output_file = self.output_dir / 'egt_analysis_report.md'
        with open(output_file, 'w') as f:
            f.write(report_text)
        
        print(f"\nâœ… Report generated: {output_file}")


def main():
    """
    Main execution function.
    """
    
    print("=" * 80)
    print("EGT PILOT ANALYSIS: EPISTEMOLOGICAL CLERGIES")
    print("=" * 80)
    print("\nPrompt 4 Implementation: Parasitic Equilibrium Modeling")
    print("Based on: Vince (2005) + CLI Framework + CSI Hypothesis")
    print()
    
    # Initialize
    output_dir = Path(__file__).parent.parent / 'results'
    analyzer = EpistemologicalClergyEGT(output_dir)
    
    # Step 1: Generate synthetic dataset
    print("\n" + "=" * 80)
    print("STEP 1: GENERATE SYNTHETIC DATASET")
    print("=" * 80)
    df = analyzer.generate_synthetic_dataset(n_jurisdictions=50)
    
    # Step 2: Run EGT analysis
    print("\n" + "=" * 80)
    print("STEP 2: RUN EGT ANALYSIS")
    print("=" * 80)
    results_df = analyzer.run_full_analysis(df)
    
    # Step 3: Identify threshold
    print("\n" + "=" * 80)
    print("STEP 3: IDENTIFY CRITICAL THRESHOLD")
    print("=" * 80)
    threshold = analyzer.identify_threshold(results_df)
    
    # Step 4: Generate visualizations
    print("\n" + "=" * 80)
    print("STEP 4: GENERATE VISUALIZATIONS")
    print("=" * 80)
    analyzer.generate_visualizations(results_df, threshold)
    
    # Step 5: Generate report
    print("\n" + "=" * 80)
    print("STEP 5: GENERATE REPORT")
    print("=" * 80)
    analyzer.generate_report(results_df, threshold)
    
    print("\n" + "=" * 80)
    print("âœ… ANALYSIS COMPLETE!")
    print("=" * 80)
    print(f"\nResults saved to: {output_dir}")
    print("\nGenerated files:")
    print("  - dataset_150_synthetic.csv (input data)")
    print("  - egt_parameters.csv (full results)")
    print("  - egt_analysis_report.md (summary)")
    print("  - csi_vs_gfunction.png (threshold visualization)")
    print("  - ess_distribution.png (classification)")
    print("  - reform_viability_heatmap.png (jurisdiction Ã— domain)")
    print("  - correlation_matrix.png (variable relationships)")
    print()


if __name__ == "__main__":
    main()
